#Import Cac Thu Vien
import tensorflow as tf
import string
import sys
import os
import pandas as pd
import numpy as np
import scipy as sp
import matplotlib.pyplot as plt

from PIL import Image
from math import log
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from keras.layers import Dropout
from pandas import read_csv
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.optimizers import SGD
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from gensim.models import Word2Vec
import gc

malwareX = ""

def detect_malware(malwareX):    
    f=open(malwareX,'r');
    dataVector=[];
    # Khởi biến chứa nội dung file đọc được
    corpus_raw0 ='' 
    # Xóa những bytes vô nghĩa trong file (00 & CC xuất hiện 5 lần)
    for line in f:
        line=line.replace('CC CC CC CC CC', '', 3)
        line=line.replace('00 00 00 00 00', '', 3)   
        
        line=line.replace('CC CC CC', 'CC', 2)
        line=line.replace('00 00 00', '00', 2)
        
        chay = len(line.split())
        if(chay<=4):
            line=line.replace('CC', '', 3)
            line=line.replace('00', '', 3)
        
        corpus_raw0 += line
    
    raw_sentence = corpus_raw0.split('\n')
    sentences = []        
    for sentence in raw_sentence:
        temp=[]
        
        for w in sentence.split()[1:]:
            if ((w!='') and (w!='??')):
                temp.append(w.lower())
        if((temp==[])): continue
        else: sentences.append(temp)
    
    f.close()
    print("\nKích thước sentences: ",len(sentences))
    
    # Nếu dữ liệu đầu vào rỗng thì bỏ qua
    if(len(sentences)!=0):
        # Xây dựng model CBOW of Word2Vec
        model = Word2Vec( sentences ,size = 256, min_count = 1, window=8, iter=3)
        #model.train( sentences , epochs= 2, total_examples = model.corpus_count)
        
        print(model)
            
        # extract all vectors(trích xuất tất cả các vector of bytes)
        words = list(model.wv.vocab)     # Biến đổi lại thành list từ vựng
        words.sort()    # Sắp xếp từ vựng lại theo thứ tự từ 00 -> ff
        
        # Tạo thành ma trận 256x256 từ word vector of byte và các bytes
        Ms = []
        for i in words:
            Ms.append(model[i])
        m = np.asmatrix(Ms)
        #print("\nShape of Ms: ",m.shape)
        
        # Normalize the elements of the matrix Ms (Chuẩn hóa)
        minMs = m.min()
        maxMs = m.max()
        newMs = (((m-minMs)/(maxMs-minMs))*255).astype(int)
        
        # Chuyển Matrix sang hình ảnh thang độ xám
        img = Image.fromarray(np.uint8(newMs))
        #img.save('kq/'+str(Y.iloc[counts])+'/'+name+'.png',"PNG")
        img.show()
        
        # Chuyển matrix 256x256 thành vector(size = 65536)
        dataVector = m.flatten()
    
    else:
        print('file malware bi nhieu');
    
    # load the model MLP from disk
    from tensorflow import keras
    from joblib import dump, load
    
    loaded_model = keras.models.load_model('../ketqua/200/model_MLP')
    
    #loaded_model = load('./ketqua/model_SVM')
    
    nhan = ['Ramnit', 'Lollipop', 'Kelihos_ver3', 'Vundo', 'Simda', 'Tracur', 'Kelihos_ver1' , 'Obfuscator.ACY', 'Gatak']
    
    # predict probabilities for test set
    y_zep = loaded_model.predict_classes(dataVector)
    
    print(loaded_model.predict(dataVector))
    
    print(nhan[y_zep[0]])
    
    del dataVector
    del loaded_model
    gc.collect();

    return nhan[y_zep[0]];

print("--------------- [The end] ------------------")

